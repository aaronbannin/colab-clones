{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaronbannin/colab-clones/blob/main/Advent_of_Haystack_Pipeline_Connecting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advent of Haystack: Day 1\n",
        "_Make a copy of this Colab to start!_\n",
        "\n",
        "In this first challenge, we are going to build a RAG pipeline that answers questions based on the contents of a URL. Most of the pipeline is ready, but your task is to complete the pipeline connections ðŸ‘‡\n",
        "\n",
        "You should complete Step 5 of this colab.\n",
        "\n",
        "### Components to use:\n",
        "1. `LinkContentFetcher`: Expects a list of URLs and returns `ByteStream` type\n",
        "2. `HTMLToDocument`: Expects a `ByteStream` and creates `Document` type.\n",
        "3. `DocumentSplitter`: This expcects a list of `Documents` and returns a list of split, preprocessed documents.\n",
        "4. `PromptBuilder`: To define the manner we want to interact with an LLM. We use Jinja templating\n",
        "5. `GPTGenereator`: Expects a fully formed prompt and queries an OpenAI GPT model."
      ],
      "metadata": {
        "id": "5q2FHwPY-wqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1) Installation\n",
        "\n",
        "**Note:** There is a known issue with colab due to a version conflict error related to `llmx` which comes with Colab. You might get an `llmx` error. You can safely ignore this, or run `pip uninstall -y llmx`"
      ],
      "metadata": {
        "id": "ZALZDx-LFebK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJJ5AT3Z79e3"
      },
      "outputs": [],
      "source": [
        "!pip install haystack-ai\n",
        "!pip install boilerpy3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2) Enter API keys for LLM and search providers\n",
        "Run this code and youâ€™ll be prompted to enter your OpenAI API Key. If you donâ€™t have a key, [follow these instructions](https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key)."
      ],
      "metadata": {
        "id": "W3jwS4A_FmEV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "openai_api_key = getpass.getpass(\"Enter OpenAI API key:\")"
      ],
      "metadata": {
        "id": "zy4xBS6v8n1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3) Create components"
      ],
      "metadata": {
        "id": "85pAAbaPFtZc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.fetchers import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.preprocessors import DocumentSplitter\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack.components.generators import GPTGenerator\n",
        "\n",
        "fetcher = LinkContentFetcher()\n",
        "converter = HTMLToDocument()\n",
        "splitter = DocumentSplitter(split_length=100, split_overlap=5)"
      ],
      "metadata": {
        "id": "oXMwKWzUAEaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Given the information below: \\n\n",
        "            {% for document in documents %}\n",
        "                {{ document.content }}\n",
        "            {% endfor %}\n",
        "            Question: {{ query }}. \\n Answer:\"\"\"\n",
        "\n",
        "prompt_builder = PromptBuilder(template = template)"
      ],
      "metadata": {
        "id": "qI4OaTHBa-vt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GPTGenerator(api_key = openai_api_key, model_name = \"gpt-4\")"
      ],
      "metadata": {
        "id": "98SZvedobVKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4) Add them to a Haystack 2.0 Pipeline"
      ],
      "metadata": {
        "id": "jnDhrfD5AayG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline\n",
        "\n",
        "pipeline = Pipeline()\n",
        "pipeline.add_component(name=\"fetcher\", instance=fetcher)\n",
        "pipeline.add_component(name=\"converter\", instance=converter)\n",
        "pipeline.add_component(name=\"splitter\", instance=splitter)\n",
        "pipeline.add_component(name=\"prompt_builder\", instance=prompt_builder)\n",
        "pipeline.add_component(name=\"llm\", instance=llm)"
      ],
      "metadata": {
        "id": "UIXUQWG5AYg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5) Connect the components\n",
        "\n",
        "Complete the pipelne connections to achieve a working pipeline that can be run\n",
        "\n",
        "**PSA:** If you are re-running this cell multiple times and you get a `PipelineConnectionError`, try restarting your Colab runtime."
      ],
      "metadata": {
        "id": "KFQOOQkaAeRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.connect(\"fetcher\", \"converter\")"
      ],
      "metadata": {
        "id": "hpDVUIhlAi0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6) Run the Pipeline"
      ],
      "metadata": {
        "id": "Y2v6GZs6Am5O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_dict ={\n",
        "    \"urls\": [\"https://haystack.deepset.ai/blog/customizing-rag-to-summarize-hacker-news-posts-with-haystack2\"],\n",
        "    \"query\": \"How do you build a custom component?\"\n",
        "}\n",
        "\n",
        "\n",
        "result = pipeline.run(data={\"fetcher\": {\"urls\": query_dict[\"urls\"]}, \"prompt_builder\": {\"query\": query_dict[\"query\"]}})"
      ],
      "metadata": {
        "id": "Gbo1QwM9Ambj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result['llm']['replies'][0])"
      ],
      "metadata": {
        "id": "daLZtg3gb7m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7) Draw the Pipeline ðŸŽ¨\n",
        "When you run this code block, it will create a new file that will appear in the \"Files\" section of Colab (see menu tab on the side)."
      ],
      "metadata": {
        "id": "z0eEFSDYAjOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.draw(\"/content/pipeline.png\")"
      ],
      "metadata": {
        "id": "ctE6bDESAqv8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}